#!/usr/bin/env python3
# -*- coding: utf-8 -*-
#! å¦‚ä¸‹è„šæœ¬å¯ä»¥åœ¨æ™®é€šç”µè„‘10ç§’å†…æŸ¥è¯¢äº”ä¸‡ä¸ªå•å€ç¾¤

from __future__ import annotations
from pathlib import Path
from functools import lru_cache
import re
import sys
import pandas as pd

# =========================== 1. ç»Ÿä¸€é…ç½® =========================== #
OUTPUT_DIR   = Path("/mnt/f/3_é™ˆé™é¡¹ç›®/2_å•å€ç¾¤åˆ†æ/output")
SRC_DIR     = Path("/mnt/f/OneDrive/æ–‡æ¡£ï¼ˆç§‘ç ”ï¼‰/è„šæœ¬/æˆ‘çš„ç§‘ç ”è„šæœ¬/Python/æ¯ç³»ä¸“ç”¨")

FILE_ID_HAP          = OUTPUT_DIR / "ID_Hap.txt"      # åŸå§‹ IDâ€‘Hapï¼ˆä¸¤åˆ—ï¼‰
FILE_CORRECTION      = SRC_DIR / "Haplogrepå•å€ç¾¤åˆ†å‹è®¢æ­£è¡¨.csv"
FILE_PHYLOTREE       = SRC_DIR / "çº¿ç²’ä½“å•å€ç¾¤phylotree(version17)2025å¹´3æœˆ12æ—¥.txt"
FILE_TARGET          = SRC_DIR / "ç›®æ ‡_YuChunLi.txt"
FILE_ROUGH_FIX       = SRC_DIR / "é”™è¯¯çº æ­£_YuChunLi.txt"

OUT_FIXED_HAP        = OUTPUT_DIR / "è®¢æ­£ä¹‹åçš„å•å€ç¾¤åç§°.txt"
OUT_FORWARD_LEVEL    = OUTPUT_DIR / "æ­£åºç­‰çº§.txt"
OUT_REVERSED_LEVEL   = OUTPUT_DIR / "é€†åºç­‰çº§.txt"
OUT_NOT_FOUND        = OUTPUT_DIR / "æ²¡æœ‰æŸ¥è¯¢åˆ°è¯·æ ¸å®.txt"
OUT_FINAL            = OUTPUT_DIR / "æœ€ç»ˆ.txt"
OUT_UNMATCHED        = OUTPUT_DIR / "æ— æ³•å¤„ç†.txt"

# =========================== 2. é€šç”¨å‡½æ•° =========================== #
_pat_strip = re.compile(r'[\*\-]|(\+.*)')

def strip_suffix(hap: str) -> str:
    """ç§»é™¤ *ã€- ä»¥åŠ + ä¹‹åçš„ä¿®é¥°ä½ç‚¹"""
    return _pat_strip.sub('', hap)

def validate_input(df: pd.DataFrame, required: list[str]) -> None:
    if not set(required) <= set(df.columns):
        raise ValueError(f"è¾“å…¥ç¼ºå°‘å¿…è¦åˆ—: {required}")

# =========================== 3. ç¬¬ä¸€æ­¥ï¼šçº æ­£ haplogroup åç§° =========================== #
def apply_primary_correction(id_hap_path=FILE_ID_HAP,
                             correction_path=FILE_CORRECTION,
                             save_path=OUT_FIXED_HAP) -> pd.DataFrame:
    id_hap = pd.read_csv(id_hap_path, sep='\t')
    validate_input(id_hap, ["ID", "Haplogroup"])

    corr_map = pd.read_csv(correction_path).set_index("Origin")["Revised"]
    id_hap["Haplogroup"] = id_hap["Haplogroup"].replace(corr_map.to_dict())

    id_hap.to_csv(save_path, sep='\t', index=False)
    return id_hap

# =========================== 4. ç¬¬äºŒæ­¥ï¼šæ„å»º PhyloTree è¿½æº¯é“¾ =========================== #
def build_parent_map(tree_path=FILE_PHYLOTREE) -> dict[str, str | None]:
    """
    å°† phylotree ç»“æ„(ä»¥åˆ¶è¡¨ç¬¦ç¼©è¿›è¡¨ç¤ºå±‚çº§)è§£ææˆ child->parent å­—å…¸
    """
    parent_map: dict[str, str | None] = {}
    stack: list[tuple[int, str]] = []                   # [(level, hap)]
    with open(tree_path, encoding='utf-8') as f:
        for raw in f:
            if not raw.strip():
                continue
            level = raw.count('\t')
            hap   = raw.strip()
            while stack and stack[-1][0] >= level:
                stack.pop()
            parent = stack[-1][1] if stack else None
            parent_map[hap] = parent
            stack.append((level, hap))
    return parent_map

def build_lineage_functions(parent_map):
    @lru_cache(maxsize=None)
    def lineage(hap: str) -> tuple[str, ...]:
        """è¿”å›ä»æ ¹åˆ°è¯¥ hap çš„è·¯å¾„(å«è‡ªèº«)"""
        path = []
        while hap:
            path.append(hap)
            hap = parent_map.get(hap)
        return tuple(reversed(path))

    return lineage

def output_level_tables(id_hap: pd.DataFrame,
                        lineage_func,
                        forward_file=OUT_FORWARD_LEVEL,
                        reverse_file=OUT_REVERSED_LEVEL,
                        not_found_file=OUT_NOT_FOUND) -> None:
    """
    ç”Ÿæˆ Level_0..n / Level_n..0 ä¸¤ä¸ªè¡¨ + æœªæ‰¾åˆ°åˆ—è¡¨
    """
    # â€”â€” è®¡ç®— lineage å¹¶ç»Ÿè®¡æœ€é•¿æ·±åº¦ â€”â€”
    id_hap["lineage"] = id_hap["Haplogroup"].map(lineage_func)
    max_len = id_hap["lineage"].str.len().max()

    # â€”â€” åˆ¶ä½œæ­£åº & é€†åºåˆ— â€”â€” 
    level_cols_fwd = [f"Level_{i}"        for i in range(max_len)]
    level_cols_rev = [f"Level_{i}"        for i in range(max_len-1, -1, -1)]

    def pad(seq: tuple[str, ...]) -> list[str]:
        seq = list(seq)
        return seq + [""] * (max_len - len(seq))

    id_hap[level_cols_fwd] = id_hap["lineage"].apply(lambda x: pd.Series(pad(x)))
    id_hap[level_cols_rev] = id_hap["lineage"].apply(lambda x: pd.Series(pad(tuple(reversed(x)))))

    # â€”â€” ä¿å­˜ â€”â€” 
    id_hap[["ID"] + level_cols_fwd].to_csv(forward_file,  sep='\t', index=False)
    id_hap[["ID"] + level_cols_rev].to_csv(reverse_file,  sep='\t', index=False)

    # â€”â€” æœªæ‰¾åˆ°ï¼šlineage ä¸ºç©º â€”â€” 
    missed = id_hap[id_hap["lineage"].str.len() == 0][["ID", "Haplogroup"]]
    if not missed.empty:
        missed.to_csv(not_found_file, sep='\t', index=False)

# =========================== 5. ç¬¬ä¸‰æ­¥ï¼šåŒ¹é…ç›®æ ‡åˆ—è¡¨ =========================== #
def match_to_target(reverse_file=OUT_REVERSED_LEVEL,
                    target_path=FILE_TARGET,
                    rough_fix_path=FILE_ROUGH_FIX,
                    out_final=OUT_FINAL,
                    out_unmatched=OUT_UNMATCHED) -> None:
    df_rev = pd.read_csv(reverse_file, sep='\t')
    validate_input(df_rev, ["ID"])

    # ç›®æ ‡é›†åˆ & ç²—çº æ­£ map
    target_set = set(pd.read_csv(target_path, header=None, names=["Hap"])["Hap"].map(strip_suffix))
    rough_map  = pd.read_csv(rough_fix_path, sep='\t', header=None,
                             names=['Original', 'Correction']).set_index("Original")["Correction"]

    level_cols = df_rev.columns[1:]          # ID åæ‰€æœ‰åˆ—

    matched, unmatched = [], []
    for _, row in df_rev.iterrows():
        seq = [strip_suffix(str(h)) for h in row[level_cols] if pd.notna(h) and str(h).strip()]
        hit = next((h for h in seq if h in target_set), None)
        if hit:
            matched.append((row["ID"], rough_map.get(hit, hit)))
        else:
            fall_back = seq[0] if seq else ""
            unmatched.append((row["ID"], fall_back))

    # â€”â€” è¾“å‡ºç»“æœ â€”â€” 
    pd.DataFrame(matched, columns=["ID", "Haplogroup_PCA"]).to_csv(out_final, sep='\t', index=False)
    pd.DataFrame(unmatched, columns=["ID", "Haplogroup"]).to_csv(out_unmatched, sep='\t', index=False)

    # â€”â€” ç‰¹æ®Š L* å¤„ç† â€”â€” 
    if unmatched and all(h.startswith("L") for _, h in unmatched if h):
        df_un = pd.read_csv(out_unmatched, sep='\t')
        df_un["Haplogroup_PCA"] = df_un["Haplogroup"].str[:2]
        pd.concat([pd.read_csv(out_final, sep='\t'), df_un[["ID", "Haplogroup_PCA"]]]
                  ).to_csv(out_final, sep='\t', index=False)

# =========================== 6. ä¸»è°ƒç”¨ =========================== #
if __name__ == '__main__':
    try:
        # 1) åŸºç¡€çº æ­£
        df_hap = apply_primary_correction()

        # 2) lineage è¡¨
        lineage = build_lineage_functions(build_parent_map())
        output_level_tables(df_hap, lineage)

        # 3) ç›®æ ‡åŒ¹é…
        match_to_target()

        print("å…¨éƒ¨æµç¨‹è¿è¡Œå®Œæ¯• âœ…")
    except Exception as e:
        print(f"ğŸ’¥ è¿è¡Œä¸­æ–­: ä¸€ä¸ªå¯èƒ½çš„åŸå› æ˜¯ç”Ÿæˆçš„ 'æ— æ³•å¤„ç†.txt' æ–‡æ¡£ä¸­å­˜åœ¨é™¤äº† L å•å€ç¾¤ä¹‹å¤–çš„å•å€ç¾¤\nè¯·æ‰‹åŠ¨åœ¨Excelç­‰è½¯ä»¶å†…å¤„ç†è¿™äº›ç‰¹æ®Šçš„æ ·æœ¬", e, file=sys.stderr)
        sys.exit(1)
