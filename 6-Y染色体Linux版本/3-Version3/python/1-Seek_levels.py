#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# å¦‚ä¸‹è„šæœ¬å¯ä»¥åœ¨æ™®é€šç”µè„‘10ç§’å†…æŸ¥è¯¢äº”ä¸‡ä¸ªå•å€ç¾¤

from __future__ import annotations
from pathlib import Path
from functools import lru_cache
import re
import sys
import argparse
import pandas as pd

# =========================== é€šç”¨å‡½æ•° =========================== #
_pat_strip = re.compile(r'[\*\-]|(\+.*)')

def strip_suffix(hap: str) -> str:
    """ç§»é™¤ *ã€- ä»¥åŠ + ä¹‹åçš„ä¿®é¥°ä½ç‚¹"""
    return _pat_strip.sub('', hap)

def validate_input(df: pd.DataFrame, required: list[str]) -> None:
    if not set(required) <= set(df.columns):
        raise ValueError(f"è¾“å…¥ç¼ºå°‘å¿…è¦åˆ—: {required}")

# =========================== æ ¸å¿ƒæ­¥éª¤ =========================== #
def apply_primary_correction(id_hap_path: Path,
                             correction_path: Path,
                             save_path: Path) -> pd.DataFrame:
    id_hap = pd.read_csv(id_hap_path, sep='\t')
    validate_input(id_hap, ["ID", "Haplogroup"])

    corr_map = pd.read_csv(correction_path).set_index("Origin")["Revised"]
    id_hap["Haplogroup"] = id_hap["Haplogroup"].replace(corr_map.to_dict())

    save_path.parent.mkdir(parents=True, exist_ok=True)
    id_hap.to_csv(save_path, sep='\t', index=False)
    return id_hap

def build_parent_map(tree_path: Path) -> dict[str, str | None]:
    """
    å°† phylotree ç»“æ„(ä»¥åˆ¶è¡¨ç¬¦ç¼©è¿›è¡¨ç¤ºå±‚çº§)è§£ææˆ child->parent å­—å…¸
    """
    parent_map: dict[str, str | None] = {}
    stack: list[tuple[int, str]] = []                   # [(level, hap)]
    with open(tree_path, encoding='utf-8') as f:
        for raw in f:
            if not raw.strip():
                continue
            level = raw.count('\t')
            hap   = raw.strip()
            while stack and stack[-1][0] >= level:
                stack.pop()
            parent = stack[-1][1] if stack else None
            parent_map[hap] = parent
            stack.append((level, hap))
    return parent_map

def build_lineage_functions(parent_map):
    @lru_cache(maxsize=None)
    def lineage(hap: str) -> tuple[str, ...]:
        """è¿”å›ä»æ ¹åˆ°è¯¥ hap çš„è·¯å¾„(å«è‡ªèº«)"""
        path = []
        while hap:
            path.append(hap)
            hap = parent_map.get(hap)
        return tuple(reversed(path))
    return lineage

def output_level_tables(id_hap: pd.DataFrame,
                        lineage_func,
                        forward_file: Path,
                        reverse_file: Path,
                        not_found_file: Path) -> None:
    """
    ç”Ÿæˆ Level_0..n / Level_n..0 ä¸¤ä¸ªè¡¨ + æœªæ‰¾åˆ°åˆ—è¡¨
    åªè¾“å‡ºåŒ…å«æ•°æ®çš„åˆ—ï¼Œä¸è¾“å‡ºå…¨ç©ºåˆ—
    """
    id_hap = id_hap.copy()
    id_hap["lineage"] = id_hap["Haplogroup"].map(lineage_func)

    # ä¸ºæ¯ä¸ªæ ·æœ¬åˆ›å»ºæ­£åºå’Œé€†åºçš„è¡Œ
    forward_rows = []
    reverse_rows = []
    
    for _, row in id_hap.iterrows():
        lineage = row["lineage"]
        fwd = [row["ID"]] + list(lineage)
        rev = [row["ID"]] + list(reversed(lineage))
        
        forward_rows.append(fwd)
        reverse_rows.append(rev)
    
    # æ‰¾åˆ°æœ€é•¿çš„è¡Œ
    max_fwd_len = max(len(row) for row in forward_rows)
    max_rev_len = max(len(row) for row in reverse_rows)
    
    # ç”Ÿæˆåˆ—å
    level_cols_fwd = ["ID"] + [f"Level_{i}" for i in range(max_fwd_len - 1)]
    level_cols_rev = ["ID"] + [f"Level_{i}" for i in range(max_rev_len - 1)]
    
    # åˆ›å»º DataFrame å¹¶åªä¿ç•™éœ€è¦çš„åˆ—æ•°
    df_fwd = pd.DataFrame(forward_rows, columns=level_cols_fwd[:max_fwd_len])
    df_rev = pd.DataFrame(reverse_rows, columns=level_cols_rev[:max_rev_len])

    forward_file.parent.mkdir(parents=True, exist_ok=True)
    reverse_file.parent.mkdir(parents=True, exist_ok=True)
    not_found_file.parent.mkdir(parents=True, exist_ok=True)

    df_fwd.to_csv(forward_file,  sep='\t', index=False)
    df_rev.to_csv(reverse_file,  sep='\t', index=False)

    # æœªæ‰¾åˆ°ï¼šlineage ä¸ºç©º
    missed = id_hap[id_hap["lineage"].str.len() == 0][["ID", "Haplogroup"]]
    if not missed.empty:
        missed.to_csv(not_found_file, sep='\t', index=False)

def match_to_target(reverse_file: Path,
                    target_path: Path,
                    rough_fix_path: Path,
                    out_final: Path,
                    out_unmatched: Path) -> None:
    df_rev = pd.read_csv(reverse_file, sep='\t')
    validate_input(df_rev, ["ID"])

    target_set = set(pd.read_csv(target_path, header=None, names=["Hap"])["Hap"].map(strip_suffix))
    rough_map  = pd.read_csv(rough_fix_path, sep='\t', header=None,
                             names=['Original', 'Correction']).set_index("Original")["Correction"]

    level_cols = df_rev.columns[1:]          # ID åæ‰€æœ‰åˆ—

    matched, unmatched = [], []
    for _, row in df_rev.iterrows():
        seq = [strip_suffix(str(h)) for h in row[level_cols] if pd.notna(h) and str(h).strip()]
        hit = next((h for h in seq if h in target_set), None)
        if hit:
            matched.append((row["ID"], rough_map.get(hit, hit)))
        else:
            fall_back = seq[0] if seq else ""
            unmatched.append((row["ID"], fall_back))

    # è¾“å‡ºç»“æœ
    out_final.parent.mkdir(parents=True, exist_ok=True)
    out_unmatched.parent.mkdir(parents=True, exist_ok=True)

    pd.DataFrame(matched, columns=["ID", "Haplogroup_PCA"]).to_csv(out_final, sep='\t', index=False)
    pd.DataFrame(unmatched, columns=["ID", "Haplogroup"]).to_csv(out_unmatched, sep='\t', index=False)

    # ç‰¹æ®Š L* å¤„ç†
    if unmatched and all(h.startswith("L") for _, h in unmatched if h):
        df_un = pd.read_csv(out_unmatched, sep='\t')
        df_un["Haplogroup_PCA"] = df_un["Haplogroup"].str[:2]
        pd.concat([pd.read_csv(out_final, sep='\t'), df_un[["ID", "Haplogroup_PCA"]]]
                  ).to_csv(out_final, sep='\t', index=False)

# =========================== å‚æ•°è§£æä¸å…¥å£ =========================== #
def parse_args():
    parser = argparse.ArgumentParser(
        description="mtDNA å•å€ç¾¤ç®¡çº¿ï¼šçº æ­£åç§° -> æ„å»ºè°±ç³» -> åŒ¹é…ç›®æ ‡",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )

    # ç›®å½•çº§åˆ«ï¼ˆè‹¥å•ä¸ªæ–‡ä»¶æœªæŒ‡å®šï¼Œåˆ™æŒ‰é»˜è®¤æ–‡ä»¶ååŸºäºç›®å½•æ¨å¯¼ï¼‰
    parser.add_argument("--output-dir", type=Path,
        default=Path("/mnt/f/3_é™ˆé™é¡¹ç›®/2_å•å€ç¾¤åˆ†æ/output"),
        help="è¾“å‡ºç›®å½•ï¼ˆå†³å®šé»˜è®¤è¾“å‡ºæ–‡ä»¶è·¯å¾„ä¸é»˜è®¤çš„ ID_Hap.txt ä½ç½®ï¼‰")
    parser.add_argument("--src-dir", type=Path,
        default=Path("/mnt/f/OneDrive/æ–‡æ¡£ï¼ˆç§‘ç ”ï¼‰/è„šæœ¬/æˆ‘çš„ç§‘ç ”è„šæœ¬/Python/æ¯ç³»ä¸“ç”¨"),
        help="æºç /èµ„æºç›®å½•ï¼ˆå†³å®šé»˜è®¤çº æ­£è¡¨ã€phylotreeã€ç›®æ ‡ã€ç²—çº æ­£æ–‡ä»¶çš„è·¯å¾„ï¼‰")

    # è¾“å…¥ä¸èµ„æºæ–‡ä»¶ï¼ˆå¯è¦†ç›–ï¼‰
    parser.add_argument("--file-id-hap", type=Path, default=None, help="åŸå§‹ ID-Hapï¼ˆä¸¤åˆ—ï¼Œåˆ¶è¡¨ç¬¦ï¼‰")
    parser.add_argument("--file-correction", type=Path, default=None, help="Haplogrep å•å€ç¾¤åˆ†å‹è®¢æ­£è¡¨.csv")
    parser.add_argument("--file-phylotree", type=Path, default=None, help="çº¿ç²’ä½“å•å€ç¾¤ phylotreeï¼ˆä»¥åˆ¶è¡¨ç¬¦ç¼©è¿›è¡¨ç¤ºå±‚çº§ï¼‰")
    parser.add_argument("--file-target", type=Path, default=None, help="ç›®æ ‡åˆ—è¡¨ï¼ˆå•åˆ—ï¼‰")
    parser.add_argument("--file-rough-fix", type=Path, default=None, help="ç²—çº æ­£è¡¨ï¼ˆä¸¤åˆ—ï¼Œåˆ¶è¡¨ç¬¦ï¼‰")

    # è¾“å‡ºæ–‡ä»¶ï¼ˆå¯è¦†ç›–ï¼‰
    parser.add_argument("--out-fixed-hap", type=Path, default=None, help="è®¢æ­£ä¹‹åçš„å•å€ç¾¤åç§°.txt")
    parser.add_argument("--out-forward-level", type=Path, default=None, help="æ­£åºç­‰çº§.txt")
    parser.add_argument("--out-reversed-level", type=Path, default=None, help="é€†åºç­‰çº§.txt")
    parser.add_argument("--out-not-found", type=Path, default=None, help="æ²¡æœ‰æŸ¥è¯¢åˆ°è¯·æ ¸å®.txt")
    parser.add_argument("--out-final", type=Path, default=None, help="æœ€ç»ˆ.txt")
    parser.add_argument("--out-unmatched", type=Path, default=None, help="æ— æ³•å¤„ç†.txt")

    return parser.parse_args()

def resolve_paths(args):
    """ç”¨ç›®å½•é»˜è®¤å€¼è¡¥é½æœªæ˜¾å¼æŒ‡å®šçš„æ–‡ä»¶è·¯å¾„"""
    OUTPUT_DIR = args.output_dir
    SRC_DIR    = args.src_dir

    FILE_ID_HAP     = args.file_id_hap     or (OUTPUT_DIR / "ID_Hap.txt")
    FILE_CORRECTION = args.file_correction or (SRC_DIR / "Haplogrepå•å€ç¾¤åˆ†å‹è®¢æ­£è¡¨.csv")
    FILE_PHYLOTREE  = args.file_phylotree  or (SRC_DIR / "çº¿ç²’ä½“å•å€ç¾¤phylotree(version17)2025å¹´3æœˆ12æ—¥.txt")
    FILE_TARGET     = args.file_target     or (SRC_DIR / "ç›®æ ‡_YuChunLi.txt")
    FILE_ROUGH_FIX  = args.file_rough_fix  or (SRC_DIR / "é”™è¯¯çº æ­£_YuChunLi.txt")

    OUT_FIXED_HAP      = args.out_fixed_hap      or (OUTPUT_DIR / "è®¢æ­£ä¹‹åçš„å•å€ç¾¤åç§°.txt")
    OUT_FORWARD_LEVEL  = args.out_forward_level  or (OUTPUT_DIR / "æ­£åºç­‰çº§.txt")
    OUT_REVERSED_LEVEL = args.out_reversed_level or (OUTPUT_DIR / "é€†åºç­‰çº§.txt")
    OUT_NOT_FOUND      = args.out_not_found      or (OUTPUT_DIR / "æ²¡æœ‰æŸ¥è¯¢åˆ°è¯·æ ¸å®.txt")
    OUT_FINAL          = args.out_final          or (OUTPUT_DIR / "æœ€ç»ˆ.txt")
    OUT_UNMATCHED      = args.out_unmatched      or (OUTPUT_DIR / "æ— æ³•å¤„ç†.txt")

    return (FILE_ID_HAP, FILE_CORRECTION, FILE_PHYLOTREE, FILE_TARGET, FILE_ROUGH_FIX,
            OUT_FIXED_HAP, OUT_FORWARD_LEVEL, OUT_REVERSED_LEVEL, OUT_NOT_FOUND, OUT_FINAL, OUT_UNMATCHED)

# =========================== ä¸»è°ƒç”¨ =========================== #
if __name__ == '__main__':
    try:
        args = parse_args()
        (FILE_ID_HAP, FILE_CORRECTION, FILE_PHYLOTREE, FILE_TARGET, FILE_ROUGH_FIX,
         OUT_FIXED_HAP, OUT_FORWARD_LEVEL, OUT_REVERSED_LEVEL, OUT_NOT_FOUND, OUT_FINAL, OUT_UNMATCHED) = resolve_paths(args)

        # 1) åŸºç¡€çº æ­£
        df_hap = apply_primary_correction(FILE_ID_HAP, FILE_CORRECTION, OUT_FIXED_HAP)

        # 2) lineage è¡¨
        lineage = build_lineage_functions(build_parent_map(FILE_PHYLOTREE))
        output_level_tables(df_hap, lineage, OUT_FORWARD_LEVEL, OUT_REVERSED_LEVEL, OUT_NOT_FOUND)

        # 3) ç›®æ ‡åŒ¹é…
        match_to_target(OUT_REVERSED_LEVEL, FILE_TARGET, FILE_ROUGH_FIX, OUT_FINAL, OUT_UNMATCHED)

        print("å…¨éƒ¨æµç¨‹è¿è¡Œå®Œæ¯• âœ…")
    except Exception as e:
        print(
            "ğŸ’¥ è¿è¡Œä¸­æ–­: ä¸€ä¸ªå¯èƒ½çš„åŸå› æ˜¯ç”Ÿæˆçš„ 'æ— æ³•å¤„ç†.txt' æ–‡æ¡£ä¸­å­˜åœ¨é™¤äº† L å•å€ç¾¤ä¹‹å¤–çš„å•å€ç¾¤ï¼›"
            "è¯·æ‰‹åŠ¨åœ¨ Excel ç­‰è½¯ä»¶å†…å¤„ç†è¿™äº›ç‰¹æ®Šæ ·æœ¬ã€‚\nè¯¦ç»†é”™è¯¯: ", e,
            file=sys.stderr
        )
        sys.exit(1)
